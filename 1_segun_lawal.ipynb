{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d2ed00",
   "metadata": {},
   "source": [
    "# EDSA - Climate Change Belief Analysis 2022\n",
    "# TeamNM6- 2201ACDS_ NM6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934217ac",
   "metadata": {},
   "source": [
    "### Notebook created by (June 2022)\n",
    "\n",
    "- #### Samuel Njoki\n",
    "- #### Mohamed Abubakar\n",
    "- #### Ubong Ben\n",
    "- #### Yinka Akindele\n",
    "- #### Segun Lawal\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74fea7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Climate Change Based On Novel Tweet Data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Increase Companies Market Research/Advertising Efficiency using Machine Learning to create Marketing tools that can identify whether or not a person believes in climate change and could possibly be converted to a new customer based on their tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d379ba5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"https://i.gifer.com/RD07.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2eb86d",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "- [Import important libraries and datasets](#section-one)\n",
    "- [A look at our datasets](#section-two)\n",
    "- [Data Pre-processing](#section-three)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6d6fb",
   "metadata": {},
   "source": [
    "# Start Comet Experiment\n",
    "We will be using Comet as version control throughout the development of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62d1507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install comet_ml\\nfrom comet_ml import Experiment\\n\\n# Setting the API key (saved as environment variable)\\nexperiment = Experiment(api_key=\"THysD8zqvW8wCiFTidV67jLP2\",\\n                        project_name=\"climate-change-belief-analysis\", \\n                        workspace=\"jamakasilwane\")                      \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip install comet_ml\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Setting the API key (saved as environment variable)\n",
    "experiment = Experiment(api_key=\"THysD8zqvW8wCiFTidV67jLP2\",\n",
    "                        project_name=\"climate-change-belief-analysis\", \n",
    "                        workspace=\"jamakasilwane\")                      \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9431ebda",
   "metadata": {},
   "source": [
    "<a id=\"section-one\"></a>\n",
    "# Importing important libraries and datasets\n",
    "We first need to load the libraries we are going to use throughout our notebook. Then load our train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b662dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Segun\n",
      "[nltk_data]     Lawal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Segun\n",
      "[nltk_data]     Lawal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Segun\n",
      "[nltk_data]     Lawal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Segun Lawal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "# import spacy\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Style\n",
    "import matplotlib.style as style \n",
    "sns.set(font_scale=1.5)\n",
    "style.use('seaborn-pastel')\n",
    "style.use('seaborn-poster')\n",
    "from PIL import Image\n",
    "# from wordcloud import WordCloud\n",
    "\n",
    "# Downloads\n",
    "# nlp = spacy.load('en')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Preprocessing\n",
    "# import en_core_web_sm\n",
    "from collections import Counter\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords, wordnet  \n",
    "from sklearn.feature_extraction.text import CountVectorizer   \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "# Building classification models\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e68ea0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and load dataset\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test_with_no_labels.csv')\n",
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6875e55",
   "metadata": {},
   "source": [
    "<a id=\"section-two\"></a>\n",
    "# A look at our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f0bfcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15819, 3)\n",
      "(10546, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.05% of tweets in train dataset are duplicate\n"
     ]
    }
   ],
   "source": [
    "# a look at the train and test datasets\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "\n",
    "percentage_duplicate = round(\n",
    "    (1 - (train['message'].nunique() / len(train['message']))) * 100, 2)\n",
    "\n",
    "print(\"{}% of tweets in train dataset are duplicate\".format(\n",
    "    percentage_duplicate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0642f2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    3640\n",
       " 0    2353\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a look at the unique values in the label column of the train dateframe\n",
    "train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b890b67a",
   "metadata": {},
   "source": [
    "The train dataset contains over 15,000 tweets while the test dataset contains over 10,000 tweets.\n",
    "\n",
    "The tweets are divided into 4 classes:\n",
    "\n",
    "* [ 2 ] News : Tweets linked to factual news about climate change.\n",
    "\n",
    "* [ 1 ] Pro : Tweets that support the belief of man-made climate change.\n",
    "\n",
    "* [ 0 ] Neutral : Tweets that neither support nor refuse beliefs of climate change.\n",
    "\n",
    "*  [-1 ] Anti : Tweets that do not support the belief of man-made climate change.\n",
    "\n",
    "10% of the messages in the train dataset were duplicated.\n",
    "\n",
    "Note: This duplicated messages are a called Retweets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da09016",
   "metadata": {},
   "source": [
    "<a id=\"section-three\"></a>\n",
    "# Data Pre-processing\n",
    "We will be preparing (cleaning and organizing) our raw data before having an in-depth Exploratory Data Analysis on the cleansed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ec43d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
