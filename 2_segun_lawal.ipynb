{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d2ed00",
   "metadata": {},
   "source": [
    "# EDSA - Climate Change Belief Analysis 2022\n",
    "# TeamNM6- 2201ACDS_ NM6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934217ac",
   "metadata": {},
   "source": [
    "### Notebook created by (June 2022)\n",
    "\n",
    "- #### Samuel Njoki\n",
    "- #### Mohamed Abubakar\n",
    "- #### Ubong Ben\n",
    "- #### Yinka Akindele\n",
    "- #### Segun Lawal\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74fea7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Climate Change Based On Novel Tweet Data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Increase Companies Market Research/Advertising Efficiency using Machine Learning to create Marketing tools that can identify whether or not a person believes in climate change and could possibly be converted to a new customer based on their tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d379ba5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"https://i.gifer.com/RD07.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2eb86d",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "- [Import important libraries and datasets](#section-one)\n",
    "- [A look at our datasets](#section-two)\n",
    "- [Data Pre-processing](#section-three)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6d6fb",
   "metadata": {},
   "source": [
    "# Start Comet Experiment\n",
    "We will be using Comet as version control throughout the development of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62d1507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install comet_ml\\nfrom comet_ml import Experiment\\n\\n# Setting the API key (saved as environment variable)\\nexperiment = Experiment(api_key=\"THysD8zqvW8wCiFTidV67jLP2\",\\n                        project_name=\"climate-change-belief-analysis\", \\n                        workspace=\"jamakasilwane\")                      \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip install comet_ml\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Setting the API key (saved as environment variable)\n",
    "experiment = Experiment(api_key=\"THysD8zqvW8wCiFTidV67jLP2\",\n",
    "                        project_name=\"climate-change-belief-analysis\", \n",
    "                        workspace=\"jamakasilwane\")                      \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9431ebda",
   "metadata": {},
   "source": [
    "<a id=\"section-one\"></a>\n",
    "# Importing important libraries and datasets\n",
    "We first need to load the libraries we are going to use throughout our notebook. Then load our train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0186836d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: conda-script.py [-h] [-V] command ...\n",
      "conda-script.py: error: unrecognized arguments: wordcloud\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31ec9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b662dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Segun\n",
      "[nltk_data]     Lawal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Segun\n",
      "[nltk_data]     Lawal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Segun\n",
      "[nltk_data]     Lawal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Segun Lawal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "# import spacy\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Style\n",
    "import matplotlib.style as style \n",
    "sns.set(font_scale=1.5)\n",
    "style.use('seaborn-pastel')\n",
    "style.use('seaborn-poster')\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Downloads\n",
    "# nlp = spacy.load('en')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Preprocessing\n",
    "# import en_core_web_sm\n",
    "from collections import Counter\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords, wordnet  \n",
    "from sklearn.feature_extraction.text import CountVectorizer   \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "# Building classification models\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68ea0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and load dataset\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test_with_no_labels.csv')\n",
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6875e55",
   "metadata": {},
   "source": [
    "<a id=\"section-two\"></a>\n",
    "# A look at our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f0bfcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15819, 3)\n",
      "(10546, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.05% of tweets in train dataset are duplicate\n"
     ]
    }
   ],
   "source": [
    "# a look at the train and test datasets\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "\n",
    "percentage_duplicate = round(\n",
    "    (1 - (train['message'].nunique() / len(train['message']))) * 100, 2)\n",
    "\n",
    "print(\"{}% of tweets in train dataset are duplicate\".format(\n",
    "    percentage_duplicate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0642f2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    3640\n",
       " 0    2353\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a look at the unique values in the label column of the train dateframe\n",
    "train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b890b67a",
   "metadata": {},
   "source": [
    "The train dataset contains over 15,000 tweets while the test dataset contains over 10,000 tweets.\n",
    "\n",
    "The tweets are divided into 4 classes:\n",
    "\n",
    "* [ 2 ] News : Tweets linked to factual news about climate change.\n",
    "\n",
    "* [ 1 ] Pro : Tweets that support the belief of man-made climate change.\n",
    "\n",
    "* [ 0 ] Neutral : Tweets that neither support nor refuse beliefs of climate change.\n",
    "\n",
    "*  [-1 ] Anti : Tweets that do not support the belief of man-made climate change.\n",
    "\n",
    "10% of the messages in the train dataset were duplicated.\n",
    "\n",
    "Note: This duplicated messages are a called Retweets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da09016",
   "metadata": {},
   "source": [
    "<a id=\"section-three\"></a>\n",
    "# Data Pre-processing\n",
    "We will be preparing (cleaning and organizing) our raw data before having an in-depth Exploratory Data Analysis on the cleansed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66ec43d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pro</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pro</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>News</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pro</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pro</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            message  tweetid\n",
       "0       Pro  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1       Pro  It's not like we lack evidence of anthropogeni...   126103\n",
       "2      News  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3       Pro  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4       Pro  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reform(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    This fuction creates a copy of the original train data, \n",
    "    converting the classes from numbers to their respective meanings\n",
    "    in words.\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    df: original dataframe\n",
    "        datatype: dataframe\n",
    "        \n",
    "    Output:\n",
    "    \n",
    "    df: modified dataframe\n",
    "        datatype: dataframe\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    df = train.copy()\n",
    "    sentiment = df['sentiment']\n",
    "    word_sentiment = []\n",
    "    \n",
    "    for word in sentiment:\n",
    "        if word == -1:\n",
    "            word_sentiment.append('Anti')\n",
    "        elif word == 0:\n",
    "            word_sentiment.append('Neutral')\n",
    "        elif word == 1:\n",
    "            word_sentiment.append('Pro')\n",
    "        else:\n",
    "            word_sentiment.append('News')\n",
    "            \n",
    "    df['sentiment'] =  word_sentiment\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = reform(train)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f2bf81",
   "metadata": {},
   "source": [
    "## Extract Hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2814414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>climate</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BeforeTheFlood</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>climatechange</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ImVotingBecause</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COP22</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hashtag  count\n",
       "19          climate    187\n",
       "24   BeforeTheFlood    129\n",
       "68    climatechange     94\n",
       "13  ImVotingBecause     62\n",
       "4             COP22     59"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_hashtag(tweet):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes in a tweet and extracts the top 15 hashtag(s) \n",
    "    using regular expressions.\n",
    "    These hashtags are stored in a seperate dataframe along with a \n",
    "    count of how frequently the occur\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    tweet: original tweets\n",
    "           datatype: 'str'\n",
    "    \n",
    "    Output:\n",
    "    df_hashtag: dataframe containing the top hashtags in the tweets\n",
    "                datatype: dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    hashtags = []\n",
    "    \n",
    "    for i in tweet:\n",
    "        ht = re.findall(r\"#(\\w+)\", i)\n",
    "        hashtags.append(ht)\n",
    "        \n",
    "    hashtags = sum(hashtags, [])\n",
    "    frequency = nltk.FreqDist(hashtags)\n",
    "    \n",
    "    hashtag_df = pd.DataFrame({'hashtag': list(frequency.keys()),\n",
    "                       'count': list(frequency.values())})\n",
    "    hashtag_df = hashtag_df.nlargest(15, columns=\"count\")\n",
    "\n",
    "    return hashtag_df\n",
    "\n",
    "# Extract the hashtag from tweets in each class\n",
    "pro = extract_hashtag(df['message'][df['sentiment'] == 'Pro'])\n",
    "anti = extract_hashtag(df['message'][df['sentiment'] == 'Anti'])\n",
    "neutral = extract_hashtag(df['message'][df['sentiment'] == 'Neutal'])\n",
    "news = extract_hashtag(df['message'][df['sentiment'] == 'News'])\n",
    "                        \n",
    "pro.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457b52a",
   "metadata": {},
   "source": [
    "## Cleaning Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ded72bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pro</td>\n",
       "      <td>polyscimajor epa chief doesn t think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pro</td>\n",
       "      <td>it s not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>News</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pro</td>\n",
       "      <td>wired was a pivotal year in the war on climate...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pro</td>\n",
       "      <td>rt it s and a racist sexist climate change den...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            message  tweetid\n",
       "0       Pro  polyscimajor epa chief doesn t think carbon di...   625221\n",
       "1       Pro  it s not like we lack evidence of anthropogeni...   126103\n",
       "2      News  rt researchers say we have three years to act ...   698562\n",
       "3       Pro  wired was a pivotal year in the war on climate...   573736\n",
       "4       Pro  rt it s and a racist sexist climate change den...   466954"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_tweet(tweet):\n",
    "    \n",
    "    # Convert tweet to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove mentions\n",
    "    tweet = re.sub('@[\\w]*', '', tweet)\n",
    "    \n",
    "    # Rwmove url's\n",
    "    tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet)\n",
    "    \n",
    "    # Remove hashtags\n",
    "    tweet = re.sub(r'#\\w*', '', tweet)\n",
    "    \n",
    "    # Remove numbers\n",
    "    tweet = re.sub(r'\\d+', '', tweet)\n",
    "    \n",
    "    # Remove punctuations\n",
    "    tweet = re.sub(r\"[,.;':@#?!\\&/$]+\\ *\", ' ', tweet)\n",
    "    \n",
    "    # Remove that funny diamond\n",
    "    tweet = re.sub(r\"U+FFFD \", ' ', tweet)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    \n",
    "    # Remove space in front of tweet\n",
    "    tweet = tweet.lstrip(' ')                        \n",
    "    \n",
    "    return tweet\n",
    "\n",
    "# Clean th tweets in the message column\n",
    "\n",
    "df['message'] = df['message'].apply(clean_tweet)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8554c",
   "metadata": {},
   "source": [
    "## Parts of speech tagging and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27b6deba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>length</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pro</td>\n",
       "      <td>polyscimajor epa chief doesn t think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>102</td>\n",
       "      <td>[polyscimajor, epa, chief, doesn, t, think, ca...</td>\n",
       "      <td>[(polyscimajor, a), (epa, n), (chief, n), (doe...</td>\n",
       "      <td>polyscimajor epa chief doesn t think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pro</td>\n",
       "      <td>it s not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>62</td>\n",
       "      <td>[it, s, not, like, we, lack, evidence, of, ant...</td>\n",
       "      <td>[(it, n), (s, v), (not, r), (like, n), (we, n)...</td>\n",
       "      <td>it s not like we lack evidence of anthropogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>News</td>\n",
       "      <td>rt researchers say we have three years to act ...</td>\n",
       "      <td>698562</td>\n",
       "      <td>86</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "      <td>[(rt, n), (researchers, n), (say, v), (we, n),...</td>\n",
       "      <td>rt researcher say we have three year to act on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pro</td>\n",
       "      <td>wired was a pivotal year in the war on climate...</td>\n",
       "      <td>573736</td>\n",
       "      <td>54</td>\n",
       "      <td>[wired, was, a, pivotal, year, in, the, war, o...</td>\n",
       "      <td>[(wired, v), (was, v), (a, n), (pivotal, a), (...</td>\n",
       "      <td>wire be a pivotal year in the war on climate c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pro</td>\n",
       "      <td>rt it s and a racist sexist climate change den...</td>\n",
       "      <td>466954</td>\n",
       "      <td>81</td>\n",
       "      <td>[rt, it, s, and, a, racist, sexist, climate, c...</td>\n",
       "      <td>[(rt, v), (it, n), (s, n), (and, n), (a, n), (...</td>\n",
       "      <td>rt it s and a racist sexist climate change den...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            message  tweetid  \\\n",
       "0       Pro  polyscimajor epa chief doesn t think carbon di...   625221   \n",
       "1       Pro  it s not like we lack evidence of anthropogeni...   126103   \n",
       "2      News  rt researchers say we have three years to act ...   698562   \n",
       "3       Pro  wired was a pivotal year in the war on climate...   573736   \n",
       "4       Pro  rt it s and a racist sexist climate change den...   466954   \n",
       "\n",
       "   length                                          tokenized  \\\n",
       "0     102  [polyscimajor, epa, chief, doesn, t, think, ca...   \n",
       "1      62  [it, s, not, like, we, lack, evidence, of, ant...   \n",
       "2      86  [rt, researchers, say, we, have, three, years,...   \n",
       "3      54  [wired, was, a, pivotal, year, in, the, war, o...   \n",
       "4      81  [rt, it, s, and, a, racist, sexist, climate, c...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0  [(polyscimajor, a), (epa, n), (chief, n), (doe...   \n",
       "1  [(it, n), (s, v), (not, r), (like, n), (we, n)...   \n",
       "2  [(rt, n), (researchers, n), (say, v), (we, n),...   \n",
       "3  [(wired, v), (was, v), (a, n), (pivotal, a), (...   \n",
       "4  [(rt, v), (it, n), (s, n), (and, n), (a, n), (...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  polyscimajor epa chief doesn t think carbon di...  \n",
       "1  it s not like we lack evidence of anthropogeni...  \n",
       "2  rt researcher say we have three year to act on...  \n",
       "3  wire be a pivotal year in the war on climate c...  \n",
       "4  rt it s and a racist sexist climate change den...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize(df):\n",
    "    \n",
    "    \n",
    "    df['length'] = df['message'].str.len()\n",
    "    df['tokenized'] = df['message'].apply(word_tokenize)\n",
    "    df['pos_tags'] = df['tokenized'].apply(nltk.tag.pos_tag)\n",
    "    \n",
    "    \n",
    "    def get_wordnet_pos(tag):\n",
    "\n",
    "        if tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "\n",
    "        elif tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "\n",
    "        elif tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "\n",
    "        elif tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "    \n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "    \n",
    "    wnl = WordNetLemmatizer()\n",
    "    df['pos_tags'] = df['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "    df['lemmatized'] = df['pos_tags'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n",
    "    df['lemmatized'] = [' '.join(map(str, l)) for l in df['lemmatized']]  \n",
    "    return df\n",
    "\n",
    "\n",
    "df = lemmatize(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b8c579",
   "metadata": {},
   "source": [
    "## Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e45f6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency(tweet):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function determines the frequency of each word in a collection of tweets \n",
    "    and stores the 25 most frequent words in a dataframe, \n",
    "    sorted from most to least frequent\n",
    "    \n",
    "    Input: \n",
    "    tweet: original tweets\n",
    "           datatype: 'str'\n",
    "           \n",
    "    Output: \n",
    "    frequency: dataframe containing the top 25 words \n",
    "               datatype: dataframe          \n",
    "    \"\"\"\n",
    "    \n",
    "    # Count vectorizer excluding english stopwords\n",
    "    cv = CountVectorizer(stop_words='english')\n",
    "    words = cv.fit_transform(tweet)\n",
    "    \n",
    "    # Count the words in the tweets and determine the frequency of each word\n",
    "    sum_words = words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, i]) for word, i in cv.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Create a dataframe to store the top 25 words and their frequencies\n",
    "    frequency = pd.DataFrame(words_freq, columns=['word', 'freq'])\n",
    "    frequency = frequency.head(25)\n",
    "    \n",
    "    return frequency\n",
    "\n",
    "# Extract the top 25 words in each class\n",
    "pro_frequency = frequency(df['lemmatized'][df['sentiment']=='Pro'])\n",
    "anti_frequency = frequency(df['lemmatized'][df['sentiment']=='Anti'])\n",
    "news_frequency = frequency(df['lemmatized'][df['sentiment']=='News'])\n",
    "neutral_frequency = frequency(df['lemmatized'][df['sentiment']=='Neutral'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e10fd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>http</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>make</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>like</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>warm</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>husband</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  freq\n",
       "20     http   359\n",
       "21     make   322\n",
       "22     like   318\n",
       "23     warm   313\n",
       "24  husband   312"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the words in the tweets for the pro and anti climate change classes \n",
    "anti_words = ' '.join([text for text in anti_frequency['word']])\n",
    "pro_words = ' '.join([text for text in pro_frequency['word']])\n",
    "news_words = ' '.join([text for text in news_frequency['word']])\n",
    "neutral_words = ' '.join([text for text in neutral_frequency['word']])\n",
    "\n",
    "# Create wordcloud for the anti climate change class\n",
    "anti_wordcloud = WordCloud(width=800, \n",
    "                           height=500, \n",
    "                           random_state=110, \n",
    "                           max_font_size=110, \n",
    "                           background_color='white',\n",
    "                           colormap=\"Reds\").generate(anti_words)\n",
    "\n",
    "# Create wordcolud for the pro climate change class\n",
    "pro_wordcloud = WordCloud(width=800, \n",
    "                          height=500, \n",
    "                          random_state=73, \n",
    "                          max_font_size=110, \n",
    "                          background_color='white',\n",
    "                          colormap=\"Greens\").generate(pro_words)\n",
    "\n",
    "# Create wordcolud for the news climate change class\n",
    "news_wordcloud = WordCloud(width=800, \n",
    "                          height=500, \n",
    "                          random_state=0, \n",
    "                          max_font_size=110, \n",
    "                          background_color='white',\n",
    "                          colormap=\"Blues\").generate(news_words)\n",
    "\n",
    "# Create wordcolud for the neutral climate change class\n",
    "neutral_wordcloud = WordCloud(width=800, \n",
    "                          height=500, \n",
    "                          random_state=10, \n",
    "                          max_font_size=110, \n",
    "                          background_color='white',\n",
    "                          colormap=\"Oranges\").generate(neutral_words)\n",
    "\n",
    "pro_frequency.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f3e65",
   "metadata": {},
   "source": [
    "# Exploratory data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae94a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
