{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "#  EDSA - Climate Change Belief Analysis 2022\n",
    "## <span style=\"color:red\"> TeamNM6 -  2201ACDS_NM6 </span>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Many companies are built around lessening one’s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received.\n",
    "\n",
    "With this context, EDSA is challenging you during the Classification Sprint with the task of creating a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    "\n",
    "Providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, the team will import the necessary libraries that will be used throughout analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "#Natural language library\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "#Other conventional libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import html\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import accuracy_score as score, classification_report\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, the team will load train and test data into a DataFrame. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load train data\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "#Load test data\n",
    "test = pd.read_csv('test_with_no_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ef4551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636088fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Data Cleaning & Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description:  ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, the team will clean the dataset and perform and indepth analysis of all the variables in the DataFrame. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a783a444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:37.824204Z",
     "start_time": "2021-06-28T08:52:37.811206Z"
    }
   },
   "source": [
    "Looking at the data, we can observe that the tweets returned contain several messy contents. \n",
    "\n",
    "First, we will remove the new lines probably generated during html decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39863588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This block of code removes \\n from each tweet\n",
    " \n",
    "for i in  (train['message']):\n",
    "    i=i.replace('\\n', '')\n",
    "    i=html.unescape(i)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0335c7",
   "metadata": {},
   "source": [
    "Great. Our data is free of messy snooky html inputs. However, there are some other problems!!!\n",
    "\n",
    "Most times twitter users attach media files like images, video etc to thier tweets. Scraping this data will caused thier conversion into JSON. This can be troublesome. We need to remove them!!!\n",
    "\n",
    "Also, we will need to clean hash characters (not hashtags); @ too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e03020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp/ipykernel_9532/1671099453.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['message'][i]=re.sub(r\"(@[A-Za-z0-9_]+)|[^\\w\\s]|http\\S+\",\"\",train['message'][i])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT  Researchers say we have three years to act...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>TodayinMaker WIRED  2016 was a pivotal year in...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT  Its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesnt think carbon dio...   625221\n",
       "1          1  Its not like we lack evidence of anthropogenic...   126103\n",
       "2          2  RT  Researchers say we have three years to act...   698562\n",
       "3          1  TodayinMaker WIRED  2016 was a pivotal year in...   573736\n",
       "4          1  RT  Its 2016 and a racist sexist climate chang...   466954"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This block of code conducts further cleaning. We will be employing\n",
    "#Regex for this task\n",
    "\n",
    "for i in range (len(train['message'])):\n",
    "    train['message'][i]=re.sub(r\"(@[A-Za-z0-9_]+)|[^\\w\\s]|http\\S+\",\"\",train['message'][i])\n",
    "train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb74182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train['sentiment'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6badd5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd6ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de51df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at feature distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data engineering ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, the team will restructure the data for the project purpose... |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1bf68d",
   "metadata": {},
   "source": [
    "For uniformity, we change all text to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "059c2f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt  researchers say we have three years to act...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>todayinmaker wired  2016 was a pivotal year in...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt  its 2016 and a racist sexist climate chang...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221\n",
       "1          1  its not like we lack evidence of anthropogenic...   126103\n",
       "2          2  rt  researchers say we have three years to act...   698562\n",
       "3          1  todayinmaker wired  2016 was a pivotal year in...   573736\n",
       "4          1  rt  its 2016 and a racist sexist climate chang...   466954"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to lowercase\n",
    "train['message']=train['message'].str.lower()\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aeb52f",
   "metadata": {},
   "source": [
    "Alright, now thats out of the way.\n",
    "The team will now perform tokenization and lemmanization. \n",
    "\n",
    "If we can recall,\n",
    "Tokenization divides text into a sequence of 'words'. Lemmanization on the other hand, groups words of similar meaning together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f77ef8",
   "metadata": {},
   "source": [
    "### Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "225e57da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tweet tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>126103</td>\n",
       "      <td>[its, not, like, we, lack, evidence, of, anthr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researchers, say, we, have, three, years,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>573736</td>\n",
       "      <td>[todayinmaker, wired, 2016, was, a, pivotal, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, its, 2016, and, a, racist, sexist, climat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  tweetid                                       tweet tokens\n",
       "0          1   625221  [polyscimajor, epa, chief, doesnt, think, carb...\n",
       "1          1   126103  [its, not, like, we, lack, evidence, of, anthr...\n",
       "2          2   698562  [rt, researchers, say, we, have, three, years,...\n",
       "3          1   573736  [todayinmaker, wired, 2016, was, a, pivotal, y...\n",
       "4          1   466954  [rt, its, 2016, and, a, racist, sexist, climat..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokeniser = TreebankWordTokenizer()\n",
    "train['tweet tokens'] = train['message'] .apply(tokeniser.tokenize)\n",
    "\n",
    "#we drop the message column\n",
    "train.drop(['message'], axis=1, inplace=True)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef9fd9",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ba68d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce40d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(words, lemmatizer):\n",
    "    return [lemmatizer.lemmatize(word) for word in words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2280f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet tokens'] = train['tweet tokens'].apply(lemma, args=(lemmatizer, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84eea17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tweet tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>126103</td>\n",
       "      <td>[it, not, like, we, lack, evidence, of, anthro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>698562</td>\n",
       "      <td>[rt, researcher, say, we, have, three, year, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>573736</td>\n",
       "      <td>[todayinmaker, wired, 2016, wa, a, pivotal, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>466954</td>\n",
       "      <td>[rt, it, 2016, and, a, racist, sexist, climate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  tweetid                                       tweet tokens\n",
       "0          1   625221  [polyscimajor, epa, chief, doesnt, think, carb...\n",
       "1          1   126103  [it, not, like, we, lack, evidence, of, anthro...\n",
       "2          2   698562  [rt, researcher, say, we, have, three, year, t...\n",
       "3          1   573736  [todayinmaker, wired, 2016, wa, a, pivotal, ye...\n",
       "4          1   466954  [rt, it, 2016, and, a, racist, sexist, climate..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "# create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1802bb",
   "metadata": {},
   "source": [
    "The team would now continue down to remove stop words. \n",
    "If we would recall, Stop words are words which do not contain important significance resulting from the fact that they commonly return a vast amount of unnecessary information.\n",
    "\n",
    "In the case of this project, we were careful to exempt 'not' from the stop words. This was to preserve context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439088a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop wards\n",
    "for i in train['tweet tokens']:\n",
    "    i=[word for word in i if not word in stopwords.words('english') and word != 'not'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b0e5f",
   "metadata": {},
   "source": [
    "Its time to do some modelling. However from the histogram obtained earlier, we observed that the four classes had uneven sizes. This particularity can cause biased predictions. So lets even out the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c310067",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train[train['sentiment']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size=4500\n",
    "resampled_classes = []\n",
    "\n",
    "# For each label\n",
    "for label in train['sentiment'].unique():\n",
    "    # Get num. of observations from this class\n",
    "    label_size = len(train[train['sentiment']==label])\n",
    "    \n",
    "    # If label_size < class size the upsample, else downsample\n",
    "    if label_size < class_size:\n",
    "        # Upsample\n",
    "        label_data = train[train['sentiment'] == label]\n",
    "        label_resampled = resample(label_data, replace=True, n_samples=class_size, random_state=27) \n",
    "    else:\n",
    "        # Downsampleresampled_data = np.concatenate(resampled_classes, axis=0)\n",
    "        label_data = train[train['sentiment'] == label]\n",
    "        label_resampled = resample(label_data, replace=False, n_samples=class_size, random_state=27)\n",
    "        \n",
    "    resampled_classes.append(label_resampled)\n",
    "    \n",
    "train = pd.concat(resampled_classes, axis=0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69aeae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in resampled_classes:\n",
    "    print(type(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79627332",
   "metadata": {},
   "source": [
    "For better prediction, we would need to convert the words into numbers (encode). We will use countvectorizer to achieve that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d33bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "count_vec = MultiLabelBinarizer()\n",
    "mlb = count_vec.fit(train['tweet tokens'])\n",
    "pd.DataFrame(mlb.transform(train['tweet tokens']), columns=[mlb.classes_])\n",
    "'''\n",
    "text = train['tweet tokens'].map(' '.join)\n",
    "count_vec = CountVectorizer()\n",
    "cv = count_vec.fit(text)\n",
    "cn=cv.get_feature_names()\n",
    "df=cv.transform(text).toarray()\n",
    "\n",
    "#Lets have a peek at the dataset\n",
    "print(pd.DataFrame((df),columns=cn).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde586d3",
   "metadata": {},
   "source": [
    "Oh wow, we have over 16,000 features. That is not good for our product as it will slow down predictions massively.\n",
    "\n",
    "We will reduce the features. We could have used countvectorizer but we want to be more purposeful than random. We wish to use the selectKBest for this. However, we will need to split the da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Import the feature selector module\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Set up selector, choosing score function and number of features to retain\n",
    "selector_kbest = feature_selection.SelectKBest(score_func=f_classif, k=1000)\n",
    "\n",
    "# Transform (i.e.: run selection on) the training data\n",
    "df = selector_kbest.fit_transform(df, train['sentiment'].values)\n",
    "print(df.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cb3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engineer existing features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section,the team would design models for the classification task. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12ad85",
   "metadata": {},
   "source": [
    "For this section, wee will extract features from our dataset, then we will model fit a model to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2cb4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58df02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(df, train['sentiment'].values, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d073e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one or more ML models\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''evaluate one or more ML models'''\n",
    "\n",
    "#Model 1: Logistic regression\n",
    "pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc9d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, we will compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "#Model 1: Logistic Regression\n",
    "print(classification_report(y_test,pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8684f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, the time will produce a visual performance comparison between the models used...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best model and motivate why it is the best choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad0c0d",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff741c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a378d64e",
   "metadata": {},
   "source": [
    "# For Submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6022a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(test['message'])):\n",
    "    test['message'][i]=test['message'][i].replace('\\n', '')\n",
    "    test['message'][i]=html.unescape(test['message'][i])\n",
    "\n",
    "for i in range (len(test['message'])):\n",
    "    test['message'][i]=re.sub(r\"(@[A-Za-z0-9_]+)|[^\\w\\s]|http\\S+\",\"\",test['message'][i])\n",
    "\n",
    "test['message']=test['message'].str.lower()\n",
    "tokeniser = TreebankWordTokenizer()\n",
    "test['tweet tokens'] = test['message'] .apply(tokeniser.tokenize)\n",
    "\n",
    "#we drop the message column\n",
    "test.drop(['message'], axis=1, inplace=True)\n",
    "test['tweet tokens'] = test['tweet tokens'].apply(lemma, args=(lemmatizer, ))\n",
    "\n",
    "for i in test['tweet tokens']:\n",
    "    i=[word for word in i if not word in stopwords.words('english') and word != 'not']\n",
    "text2 = test['tweet tokens'].map(' '.join)\n",
    "cv = count_vec.fit(text2)\n",
    "cn2=cv.get_feature_names()\n",
    "df=cv.transform(text2).toarray()\n",
    "df=pd.DataFrame((df),columns=cn2)\n",
    "\n",
    "test_df=[]\n",
    "for word in cn:\n",
    "    if word in cn2:\n",
    "        test_df.append(df[word])\n",
    "    else:\n",
    "        test_df.append(pd.DataFrame(0 for i in range(df.shape[0])))\n",
    "test_df=pd.concat(test_df, axis=1)\n",
    "test_df=selector_kbest.transform(test_df.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4478fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f854fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=pd.DataFrame(dict())\n",
    "res['tweetid']=test['tweetid']\n",
    "res['sentiment']=pred\n",
    "\n",
    "print(res.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('submission_TeamNM6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08cf03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb488c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment with your api key\n",
    "\n",
    "experiment = Experiment(\n",
    "    api_key=\"vYZLU5qF1hfDnC1UNRgZopRTg\",\n",
    "    project_name=\"2201acds-nm6\",\n",
    "    workspace=\"yinka-akindele\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
